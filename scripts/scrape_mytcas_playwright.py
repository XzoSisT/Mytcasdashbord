from bs4 import BeautifulSoup
from playwright.sync_api import sync_playwright
import pandas as pd
import re
import time

keywords = ["‡∏ß‡∏¥‡∏®‡∏ß‡∏Å‡∏£‡∏£‡∏°‡∏Ñ‡∏≠‡∏°‡∏û‡∏¥‡∏ß‡πÄ‡∏ï‡∏≠‡∏£‡πå", "‡∏ß‡∏¥‡∏®‡∏ß‡∏Å‡∏£‡∏£‡∏°‡∏õ‡∏±‡∏ç‡∏ç‡∏≤‡∏õ‡∏£‡∏∞‡∏î‡∏¥‡∏©‡∏ê‡πå"]
base_url = "https://course.mytcas.com"
output_file = "tuition_fees.xlsx"
all_programs = []

# ‡∏î‡∏∂‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÄ‡∏î‡∏¥‡∏°‡∏à‡∏≤‡∏Å Excel (‡∏ñ‡πâ‡∏≤‡∏°‡∏µ)
try:
    existing_df = pd.read_excel(output_file)
    existing_links = set(existing_df["‡∏•‡∏¥‡∏á‡∏Ñ‡πå"].tolist())
except FileNotFoundError:
    existing_df = pd.DataFrame()
    existing_links = set()

# ‡∏ü‡∏±‡∏á‡∏Å‡πå‡∏ä‡∏±‡∏ô‡∏´‡∏≤‡∏Ñ‡πà‡∏≤‡πÉ‡∏ä‡πâ‡∏à‡πà‡∏≤‡∏¢‡∏à‡∏≤‡∏Å <dt> + <dd>
def extract_fee_from_dt_dd(soup):
    dt_tags = soup.find_all("dt")
    for dt in dt_tags:
        if "‡∏Ñ‡πà‡∏≤‡πÉ‡∏ä‡πâ‡∏à‡πà‡∏≤‡∏¢" in dt.get_text(strip=True):
            dd = dt.find_next_sibling("dd")
            if dd:
                fee_line = dd.get_text(strip=True)
                return fee_line
    return None

# ‡∏ü‡∏±‡∏á‡∏Å‡πå‡∏ä‡∏±‡∏ô fallback ‡∏´‡∏≤‡∏Å‡πÑ‡∏°‡πà‡∏°‡∏µ <dt> + <dd>
def extract_fee_text(tag):
    if not tag:
        return "‡πÑ‡∏°‡πà‡∏û‡∏ö"
    full_text = tag.get_text(separator="\n", strip=True)
    lines = full_text.splitlines()
    matched_lines = [line for line in lines if ("‡∏Ñ‡πà‡∏≤‡πÉ‡∏ä‡πâ‡∏à‡πà‡∏≤‡∏¢" in line or "‡∏Ñ‡πà‡∏≤‡πÄ‡∏ó‡∏≠‡∏°" in line) and re.search(r"\d[\d,\.]*\s*‡∏ö‡∏≤‡∏ó", line)]
    if matched_lines:
        return " / ".join(matched_lines)
    fallback_lines = [line for line in lines if re.search(r"\d[\d,\.]*\s*‡∏ö‡∏≤‡∏ó", line)]
    return " / ".join(fallback_lines) if fallback_lines else "‡πÑ‡∏°‡πà‡∏û‡∏ö"

with sync_playwright() as p:
    browser = p.chromium.launch()
    page = browser.new_page()

    for keyword in keywords:
        print(f"üîç ‡∏Ñ‡πâ‡∏ô‡∏´‡∏≤: {keyword}")
        page.goto(base_url, wait_until="networkidle")
        page.wait_for_selector("input#search")

        search_input = page.locator("input#search")
        search_input.click()
        search_input.type(keyword, delay=100)
        time.sleep(1.5)
        search_input.press("ArrowDown")
        search_input.press("Enter")
        time.sleep(2)

        content = page.inner_html("ul.t-programs")
        soup = BeautifulSoup(content, "html.parser")

        for li in soup.find_all("li"):
            try:
                a_tag = li.find("a")
                href = a_tag["href"]
                full_url = base_url + href

                if full_url in existing_links:
                    continue  # ‡∏Ç‡πâ‡∏≤‡∏°‡∏ñ‡πâ‡∏≤‡πÄ‡∏Ñ‡∏¢‡∏î‡∏∂‡∏á‡∏°‡∏≤‡πÅ‡∏•‡πâ‡∏ß

                title = li.find("h3").get_text(strip=True)
                faculty = li.find("b").get_text(" ", strip=True)
                university = li.find_all("span")[-1].get_text(strip=True)

                # ‡πÄ‡∏Ç‡πâ‡∏≤‡πÑ‡∏õ‡∏¢‡∏±‡∏á‡∏´‡∏ô‡πâ‡∏≤‡∏´‡∏•‡∏±‡∏Å‡∏™‡∏π‡∏ï‡∏£
                page.goto(full_url, wait_until="networkidle")
                time.sleep(1)

                html = page.content()
                soup_detail = BeautifulSoup(html, "html.parser")

                # ‡∏´‡∏≤‡∏Ñ‡πà‡∏≤‡πÄ‡∏ó‡∏≠‡∏°
                fee_text = extract_fee_from_dt_dd(soup_detail)
                if not fee_text:
                    fee_tag = soup_detail.find(lambda tag: tag.name in ["div", "section", "td", "p"]
                                               and any(kw in tag.get_text() for kw in ["‡∏Ñ‡πà‡∏≤‡πÉ‡∏ä‡πâ‡∏à‡πà‡∏≤‡∏¢", "‡∏Ñ‡πà‡∏≤‡πÄ‡∏ó‡∏≠‡∏°"]))
                    fee_text = extract_fee_text(fee_tag)

                all_programs.append({
                    "‡∏´‡∏•‡∏±‡∏Å‡∏™‡∏π‡∏ï‡∏£": title,
                    "‡∏°‡∏´‡∏≤‡∏ß‡∏¥‡∏ó‡∏¢‡∏≤‡∏•‡∏±‡∏¢": university,
                    "‡∏Ñ‡∏ì‡∏∞": faculty,
                    "‡∏•‡∏¥‡∏á‡∏Ñ‡πå": full_url,
                    "‡∏Ñ‡πà‡∏≤‡πÉ‡∏ä‡πâ‡∏à‡πà‡∏≤‡∏¢": fee_text.strip() if fee_text else "‡πÑ‡∏°‡πà‡∏û‡∏ö"
                })
                print(f"‚úÖ ‡∏î‡∏∂‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•: {title} - {university}")

            except Exception as e:
                print(f"‚ùå ‡πÄ‡∏Å‡∏¥‡∏î‡∏Ç‡πâ‡∏≠‡∏ú‡∏¥‡∏î‡∏û‡∏•‡∏≤‡∏î: {e}")
                continue

    browser.close()

# ‡∏£‡∏ß‡∏°‡∏Å‡∏±‡∏ö‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÄ‡∏Å‡πà‡∏≤
new_df = pd.DataFrame(all_programs)
if not existing_df.empty:
    final_df = pd.concat([existing_df, new_df], ignore_index=True)
else:
    final_df = new_df

# ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡∏•‡∏á Excel
final_df.to_excel(output_file, index=False)
print(f"\nüìÑ ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î‡πÅ‡∏•‡πâ‡∏ß‡∏ó‡∏µ‡πà: {output_file}")
